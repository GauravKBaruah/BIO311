\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{bbold}
\usepackage{tikz}
%\usepackage{silence}
\usepackage{mdframed}
%\WarningFilter{mdframed}{You got a bad break}
\usepackage[colorinlistoftodos]{todonotes}
%\usepackage{listings}
\usepackage{listingsutf8}
\usepackage{color}
\colorlet{exampcol}{blue!10}
\usepackage{multicol}
\usepackage[answerdelayed]{exercise}
\usepackage{booktabs}
\usepackage{caption}

\title{BIO311: Population Ecology\\ \textit{Prac 9: Population Matrices \& LTRE}}

\setcounter{tocdepth}{1} % Determines the depth of the table of contents;; 0:chapters, 1: chapters and sections, 2: chapters,sections and subsections

%\renewcommand{\theExercise}{\thechapter.\arabic{Exercise}}%

\begin{document}
\input{../authors}
<<setup, cache=FALSE, include=FALSE>>=
opts_chunk$set(dev="tikz",tidy=F,dev.args=list(pointsize=7.5))
options(width=60)

@

<<setparameters,echo=FALSE,include=FALSE>>=

@
\maketitle
\tableofcontents
\vspace{3cm}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% LTREs %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Life Table Response Experiment}
Life table response experiments (LTREs) are used to assess which  differences in vital rates lead to a change in $\lambda$ in an experimental design. The experiment you performed on the rotifers is well suited to be analysed by an LTRE. More information on the LTREs can be find in Caswell (2001) \textit{Matrix population models}, this is also the book that we based the theoretical background of this practical on. Before analysing the rotifer data, we will first perform a simple LTRE analysis on different data. During this part of the practical, we will write some of the functions that we will use later to analyse the rotifer data. In practical 6 (last tuesday) we had a short introduction on functions. We repeat (and slightly extend) it here, to refresh your memory.
\begin{mdframed}
\textbf{Functions} so far we have worked with variables that represent a value or set of values, for example \texttt{rot} is a variable that we have defined that contains our data. A function is in a sense a variable that does not contain values, but instead contains a set of tasks. When you call a variable, \texttt{R} will show the value of that variable. When you call a function, \texttt{R} will perform the set of tasks in that function. In general when you want to define a function, it will look like this:
<<fnc00,eval=FALSE>>=
name_of_new_function <- function(input_1,input_2,...){

  do stuff
  
  return(output)
}
@
Let's try to make that less abstract with an example:
<<fnc1>>=
x_sq <- function(x){
  return(x^2)
}

x_sq(3)
@
Here we have first defined a function (\texttt{x\textunderscore sq}) that takes one input variable (\texttt{x}). This function returns the squared value of the input. We can use the function by typing \texttt{x\textunderscore sq(x)}. The advantage of a function as that we don't have to rewrite the code all the time. If we now want to square a different number, we can just type:
<<fnc111>>=
x_sq(5)

x_sq(7)
@
Of course, this is not very usefull when the operation that we perform is just simply squaring a number, but when the operations (or set of operations) become more complicated, functions are a great way to save time.

Similarly we can also make a function that adds up two numbers and returns the squared sum:
<<fnc2>>=
x_y_sq <- function(x,y){
  ans <- x + y
  return(ans^2)
}
x_y_sq(3, 4)
@
One important thing to realise is that things that happen in a function, usually stay in a function (there are ways around this, but in general it is good practice to keep it that way). This means that the tasks in the function are performed in their own 'world' and as soon as the function is executed, the changes are gone.
<<fnc3>>=
x_y_sq <- function(x,y){
  ans <- x + y
  return(ans^2)
}
x_y_sq(3, 4)
ans
@
We now get an error, because \texttt{ans} only exists in the function and is deleted as soon as the function is completed. 
<<fnc4>>=
ans <- 4
x_y_sq <- function(x,y){
  ans <- x + y
  return(ans^2)
}
x_y_sq(3, 4)
@
What will now be the value of \texttt{ans}?

We have seen that we can not access the version of \texttt{ans} that 'lives' inside the function anymore, once the function has run. If you change anything in a function, you best return these changes to \texttt{R} at the end of the function using \texttt{return()}. Please note that when a function executes \texttt{return(x)}, \texttt{x} is given back to \texttt{R} and anything that comes after it will not be executed.
\end{mdframed}

We will now write a function that calculates the sensitivities of $\lambda$ to the matrix elements. Writing a general function, will make it easier for us to calculate sensitivities for matrices later (which we will do frequently). We provide two options for doing so: by numerical perturbation as we did in the previous practical, or by using the exact solution. The latter is conceptually more difficult, but more precise and less code. You may choose yourself which one you want to implement. Do try to write your function such that it can handle matrices with different sizes.

\begin{mdframed}\textbf{A: Sensitivities using perturbations}\\
Yesterday we have calculated the sensitivities for a barn owl population. We can now re-use that code and put it in a function, so we can use it to from now on easily calculate sensitivities for new matrices. Below the outline is given.
<<numm_approx_run,echo=FALSE>>=
A<-matrix(runif(4),ncol=2)
sens1 <- function(A){
  da <- 1e-4
  lam <- eigen(A)$value[1]
  dim <- ncol(A)
  output <- matrix(NA,ncol=dim,nrow=dim)
  for(i in 1:nrow(A)){
    for(j in 1:ncol(A)){
      TempA <- A
      TempA[i,j] <- A[i,j] + da
      TemLam <- eigen(TempA)$value[1]
      output[i,j] <- (TemLam - lam) /da
    }
  }
  output <- Re(output)
  return(output)
}
@
<<numm_approx_text,eval=FALSE>>=
# We are going to make a function with the name
# sens, that takes 1 input variable: a matrix. We call this
# matrix A. Everything between { and } is the code
# of the function. At the end the function uses return()
# to give back the calculated values of the sensitivities
sens <- function(A){

  da <- 1e-4 # define a small perturbation
  lam <- ...  # extract the dominant eigenvalue of A
  dim <- ... # store the size of A. Use ncol()
             # use ?ncol to see what it does
  
  # finally, create an empty matrix to store your results in
  output <- matrix(0,ncol=dim,nrow=dim)
  
  # loop over all indices [i,j] in A, rows and columns
  # to calculate the sensitivity of each and every index
  for(i in ...){
    for(j in ...){
      TempA <- A # we copy the matrix
      TempA[i,j] <- ... # we perturb one element
      TemLam <- ... # get lambda of the perturbed matrix
      output[i,j] <- ... # calculate the sensitivity of 
                         #lambda to a[i,j] (dlambda/da)
    }
  }
  
  # In higher dimensions, some eigenvalues may have complex parts
  # These are not relevant for the sensitivity analysis 
  # (because the sensitivities will not have complex parts)
  # we still add the following line to R to make sure that R does
  # not annoy us constantly by adding a +0i (+ an imaginary part of 0)
  # to the outcomes
  output <- Re(output)
  
  return(output) # The end of the function is reached, 
                 # we now return the value of output
}
@
\end{mdframed}

\begin{mdframed}
\textbf{B: Sensitivities using the exact solution}\\
Here we will use the formula that was shown in the lecture:
\begin{equation}
\begin{pmatrix} 
\frac{\partial \lambda}{\partial a_{1,1}} & \frac{\partial \lambda}{\partial a_{1,2}} & \dots & \frac{\partial \lambda}{\partial a_{1,N}} \\ 
\frac{\partial \lambda}{\partial a_{2,1}} & \frac{\partial \lambda}{\partial a_{2,2}} & \dots & \frac{\partial \lambda}{\partial a_{2,N}}\\
\vdots & \vdots & & \vdots \\
\frac{\partial \lambda}{\partial a_{N,1}} & \frac{\partial \lambda}{\partial a_{N,2}} & \dots & \frac{\partial \lambda}{\partial a_{N,N}} \\ 
\end{pmatrix}
=
 \frac{\vec{v} \vec{w}^T}{\vec{v}^T \vec{w}}
\end{equation}
Here, $\vec{w}$ and $\vec{v}$ are the dominant right and left eigenvector respectively. Furthermore $\vec{v}^T$ responds to the transpose of $\vec{v}$ (try \texttt{?t} in \texttt{R}). The product of two vectors can be performed in \texttt{R} by using the \texttt{\%*\%} operator. Using this we can now wite a function to calculate the sensitivities:
<<exact_approach_show,eval=FALSE>>=
sens <- function(A){
  w <- ...
  v <- ...
  outcome <- ... / as.numeric(...)
  # here we have to add the as.numeric argument.
  # this is just a problem of R:
  # it sees that the number comes from a vector
  # multiplication and therefore stores it as a matrix
  # with dimension 1x1. However, it then has difficulties
  # to divide a matrix by another matrix. We therefore
  # explicitly have to tell R that this 1x1 matrix is just
  # a number.
  
  # Next: we delete the imaginary part:
  outcome <- Re(outcome)
  return(outcome)
}
@
<<exact_approach,echo=FALSE>>=
sens <- function(A){
  w <- eigen(A)$vector[,1]
  v <- eigen(t(A))$vector[,1]
  outcome <- v %*% t(w) / as.numeric(t(v)%*%w)
  
  outcome <- Re(outcome)
  return(outcome)
}
@
\end{mdframed}
Now test your function on the following two matrices, to make sure that it works.
<<secretpopbio,include=FALSE>>=
library(popbio)
@
<<goat>>=
A <- matrix(c(0.5,0.3,0.75,0.9),nrow=2)
sens(A)

B <- matrix(c(0.5,0.3,0.7,0.9,0.3,0.2,0.4,0.8,0),nrow=3)
sens(B)
@
This is a very good start! We now have a function that easily provides us with the sensitivity values for any matrix. From here, we can finally think about more biological problems!
\subsection{Comparison of two populations of mice}
We will now continue with the more biological part of the practical and examine two populations of yellow-necked mice. 

\begin{figure}[h]
\centering
\includegraphics[width=0.3\textwidth]{mouse.jpg}
\caption{\label{fig:mice}yellow-necked mouse, from wikipedia.}
\end{figure}

This species lives mostly in woodlands and it is suspected that its distribution is limited by altitude. Let us compare a population living in the mountain (population $\boldsymbol{M}$) with a population living in the plain (population $\boldsymbol{P}$) to see if the altitude is a limiting distribution factor. This species can be described by a life-cylce in two stages; juveniles and adults. Thus the matrices describing those populations are given by:
<<t20,echo=F,eval=T, include=FALSE>>=
P<-matrix(c(0,0.25,2,0.5), nrow=2)
M<-matrix(c(0,0.2,1.9,0.45), nrow=2)

library(popbio)
lamP<-lambda(P)
lamM<-lambda(M)
lamP
lamM
@
\begin{equation}
\boldsymbol{P}=\begin{pmatrix}
\Sexpr{P[1,1]}&\Sexpr{P[1,2]}\\
\Sexpr{P[2,1]}&\Sexpr{P[2,2]}
\end{pmatrix}
\end{equation}
and
\begin{equation}
\boldsymbol{M}=\begin{pmatrix}
\Sexpr{M[1,1]}&\Sexpr{M[1,2]}\\
\Sexpr{M[2,1]}&\Sexpr{M[2,2]}
\end{pmatrix}
\end{equation}
Find the asymptotic growth rates of these populations. You can see that they differ. We would now like to investigate which matrix elements contribute the most to the difference in the asymptotic growth rates between the two populations. As before, we will start by looking at the sensitivities: which parameter seems to have the biggest effect on $\lambda$?

The sensitivites give us an idea of what might happen in the future. It shows how much $\lambda$ would increase if a matrix elemant increases with a certain amount. For this, we look at the equations. As we have shown before:
\begin{equation}
s_{i,j} = \frac{\partial \lambda}{\partial a_{i,j}}
\end{equation}
from this it also follows that:
\begin{equation}
s_{i,j} \partial a_{i,j} = \partial \lambda
\end{equation}
So what we see is that if a matrix element increases with an amount of $\partial a_{i,j}$, $\lambda$ will increase with an amount of $\partial \lambda$. For our population however, we know how big the difference in $a_{i,j}$ are from looking at the differences between the matrices (for example, there is a difference of \Sexpr{P[2,1]}-\Sexpr{M[2,1]}=\Sexpr{M[2,1]-P[2,1]} in the maturation rate between the two populations). If we want to know how much each of these differences contributes to differences in $\lambda$, all we have to do with these differences is multiply them with the sensitivities of the corresponding elements.

There is one problem however, which sensitivities do we take? The ones from $\boldsymbol{M}$ or the ones from $\boldsymbol{P}$? In practice what we do is that we use the sensitivities of the average matrix, to make sure that our sensitivities are not biased towards one of the two matrices. 

Using these values, we can describe the asymptotic growth rate of the mountain population matrix, $\boldsymbol{M}$, as a function of the asymptotic growth rate of the plain population matrix, $\boldsymbol{P}$ , our reference population plus a treatment effect:  
\begin{equation}\label{a}
\lambda^{(M)} \approx \lambda^{(P)}+\sum_{i,j}{(a^{(M)}_{ij}-a^{(P)}_{ij})} \frac{ \partial\lambda^{A}}{\partial a^{A}_{ij}}
\end{equation}
Below we explain the different terms:
\begin{itemize}
\item $\lambda^{(P)}$ is the asymptotic growth rate of the $\boldsymbol{P}$ matrix. 
\item The term ${(a^{(M)}_{ij}-a^{(P)}_{ij})}$, is the change in the elements of the matrix due to the treatment effect, here the moutain habitat. It tells us how different an element in matrix $\boldsymbol{M}$ is from the element at the same position in matrix $\boldsymbol{P}$.
\item The last part, $\frac{ \partial\lambda^{A}}{\partial a^{A}_{ij}}$, is the sensitivities of the asymptotic growth rate of a "mid-way" matrix to elements of that "mid-way" matrix. This matrix is the mean between $\boldsymbol{P}$ and $\boldsymbol{M}$ and is thus given by 
\begin{equation}
\boldsymbol{A}=\frac{\boldsymbol{M}+\boldsymbol{P}}{2}
\end{equation}
The matrix $\boldsymbol{A}$ is used because we need a matrix to compare matrices $\boldsymbol{P}$ and $\boldsymbol{M}$ against. It is possible to use either matrix $\boldsymbol{P}$ or $\boldsymbol{M}$ instead but this would give more weight to the selected matrix. Therefore we use the matrix that lies just in between.
\item The multiplication of the sensitivities with the summation term defines how much the change in each elements of the matrix due to the treatment affects the asymptotic growth rate. In other word they are the contributions of the $a_{ij}$ to the effect of the habitat on the growth. It is necessary to do this because for example, a large difference between the elements in the same position may in fact have little effect on the growth if the senstitivity for this position is low. 
\end{itemize}

You may have recognized that equation \ref{a} is a linear equation ($y=b+ax$). This method makes the assumption that the relationship between the matrices is linear and that the slope of this equation is given by $\frac{ \partial\lambda^{A}}{\partial a^{A}_{ij}}$.


With equation \ref{a}, find the value of $\lambda^{(\boldsymbol{M})}$ using \texttt{R} and compare it to the value you found earlier. How different are they? More interestingly: which difference in the matrix elements is mainly responsible for this difference? Is it the juvenile survival, the adult survival or the reproductive rate?\\[1.5ex]

\textit{Hint} Find the "mid-way" matrix. For the sensitivities.
<<t21,echo=F,eval=T, results='hide'>>=
P<-matrix(c(0,0.25,2,0.5), nrow=2)
M<-matrix(c(0,0.2,1.9,0.45), nrow=2)

#Short cut:
library(popbio)

A<-(M+P)/2
lamP<-lambda(P)
lamM<-lambda(M)
lamM2<-lamP+sum((M-P)*sensitivity(A))


#alternative complete code:
a<-0.01
Sen<-matrix(NA,2,2)
lamA<-lambda(A)
for (i in 1:2){
  for (j in 1:2){
  Ap<-A
  Ap[i,j]<-A[i,j]+a
  Sen[i,j]<-(lambda(Ap)-lamA)/a
}
}
Sen
lamP<-which(eigen(P)$values==max(eigen(P)$values))
lamP+sum((M-P)*Sen)


@
\section{Rotifer data analysis}
In this section, you will apply a factorial LTRE to the rotifer data to compare the layers "peak", "pollution" and "recovery". The second factor is the copper treatment with the levels "low", "high", "medium".

\subsection{Rate estimation}
Before we can start with the analysis of the population matrices, we first need... the matrices and thus the rates (survival and reproduction). Here, we have only two stages: juveniles and adults, so we consider a $2\times 2$ matrix. First, we load in the data (we have now uploaded a new data file on OLAT that does not containt the errors that we introduced for the previous labsession):
<<LoadDat>>=
Rot <- read.csv("rotifer_data.csv")
@
Next, we use the function \texttt{reshape()} to change the format of the data. This will later make it easier to calculate the rates. Make sure that you understand how this function changes the data!
<<Reshape_dat>>=
Roti<-reshape(Rot,timevar="Day",idvar=c("Clone","Copper","Layer"),direction="wide")
@
We will now continue and calculte the rates, for this, we first create a new data frame to store the rates in. This data frame is basically 
<<Make_dat>>=
Rates <- Roti[,1:3] 
@
Before we start, draw a 2 stage life cycle for the rotifers, this will make it easier to keep track of what is happening. We shall now first calculate the adult survival rate for the period from day $1$ to day $2$. We start by looking at adult survival. We assume that we counted all dead individuals. Now, the survival rate can easily be calculated, it should be the number of alive adults on the first day, minus the number of dead adults observed on the second day, divided by the number of alive adults in the first time step.
<<Rates>>=
Rates$Sa1 <- (Roti$Live_Adult.1 - Roti$Dead_Adult.2)/ Roti$Live_Adult.1
@
Next, we look at the maturation rate. We have already calcuated how many adults survived from day 1, to day 2. The total number of adults on day 2 will however be higher than this number. The additional adults should have arrived due to maturation of juveniles. Calculate the maturation rates (the following expression is incomplete):
<<Ratsekkk,eval=FALSE>>=
Rates$M1 <- (Roti$Live_Adult.2 - ....) / ...
@
<<Rates_2,echo=FALSE>>=
Rates$M1 <- (Roti$Live_Adult.2 + Roti$Dead_Adult.2 - Roti$Live_Adult.1) / Roti$Live_Juv.1
@
When we look into the calculated maturation rates, we will see that it is sometimes higher than 1. The reason is that we have uncertainty in our count data, maybe an adult too many was counted on day 2, or maybe a juvenile too few on day 1. An alternative explanation is that we assume only 1 transition to take place, it is however theoretically possible that within 1 day a juvenile is born and already grows up to the adult stage. Since we have only very few entries that display such problems, we will cut off the maturation rate at 1: we know that it should not be higher than 1. Uncertainty in the data should not change that theoretical assumption.
<<Rates_topoff>>=
Rates$M1[Rates$M1 > 1] <- 1
@
The next rate is the probability for a juvenile to survive but stay a juvenile. Alive juveniles at day 1 that did not mature and that were not observed dead on day 2, should have survived and stayed in the same stage:
<<Rates_3,eval=FALSE>>=
Rates$Sj1 <- (Roti$Live_Juv.1 - ... - ...)/...
@
This time we see a few cases were survival is found to be negative. We account for it by setting these rate (again there are not many cases) to zero.
<<Ratesssse,echo=FALSE>>=
Rates$Sj1 <- (Roti$Live_Juv.1 - Roti$Dead_Juv.2 - Roti$Live_Juv.1*Rates$M1) / Roti$Live_Juv.1
@
<<uzinilaki>>=
Rates$Sj1[Rates$Sj1 < 0] <- 0
@
Finally we arrive at the last rate: fecundity. Any juveniles observed on day 2, that are not surviving juveniles from day 1, must be new offspring. Calculate the fecundity rates from this concept:
<<oioi,eval=FALSE>>=
Rates$R1 <- ...
@
Fortunately, for these rates, no weird values are found. Now continue and calculate the rates for the transition from day 2 to day 3. Check for every rate if some illogical values are calculated and correct them before continuing with the calculation of the next rate.
<<douhsdjng,eval=FALSE>>=
Rates$Sa2 <- ...
Rates$M2 <- ...
Rates$Sj2 <- ...
Rates$R2 <- ...
@
<<doin,echo=TRUE>>=
Rates$R1 <- (Roti$Live_Juv.2 - Roti$Live_Juv.1*Rates$Sj1) / Roti$Live_Adult.1

# 2 --> 3
Rates$Sa2 <- (Roti$Live_Adult.2 - Roti$Dead_Adult.3)/ Roti$Live_Adult.2
Rates$M2 <- (Roti$Live_Adult.3 + Roti$Dead_Adult.3 - Roti$Live_Adult.2) / Roti$Live_Juv.2
Rates$M2[Rates$M2 > 1] <- 1
Rates$Sj2 <- (Roti$Live_Juv.2 - Roti$Dead_Juv.3 - Roti$Live_Juv.2*Rates$M2) / Roti$Live_Juv.2
Rates$Sj2[Rates$Sj2 < 0] <- 0
Rates$R2 <- (Roti$Live_Juv.3 - Roti$Live_Juv.2*Rates$Sj2) / Roti$Live_Adult.2
Rates$R2[Rates$R2 < 0] <- 0
@
We can now plot what these rates look like. For this it is easiest to first reshape the rates. The following two commands allow you to generate a boxplot of the rates for the transition of day 1 to day 2:
<<boxplot1,eval=FALSE>>=
library(tidyr)
Rates_plot <- gather_(Rates,"Rate","Value",c("Sj1","Sa1","M1","R1"))
boxplot(Value~Copper+Rate,Rates_plot)
boxplot(Value~Layer+Rate,Rates_plot)
@
Here, we use \texttt{gather\_}, try to understand what it does. Then we use \texttt{boxplot}. Here, the first argument specifies what is plotted (in this case the column \texttt{Value} is plotted, but it is split out by the categories \texttt{Copper} and \texttt{Rate} for the first plot. This is parsed to the function by the code \texttt{Value $\sim$ Copper + Rate}, this can be read as: plot the numbers in the column Value, but split them up according to both Copper and Rate). Adapt this code to also plot the rates for the second transition.
<<boxplot2,include=FALSE,eval=FALSE>>=
Rates_plot <- gather_(Rates,"Rate","Value",c("Sj2","Sa2","M2","R2"))
boxplot(Value~Copper+Rate,Rates_plot)
boxplot(Value~Layer+Rate,Rates_plot)
@
Alternatively you may consider using \texttt{ggplot()} to obtain -- depending on your taste -- nicer looking plots.
<<boxplot3,eval=FALSE>>=
library(ggplot2)
ggplot(Rates_plot,aes(factor(Copper),Value,fill=Rate)) + geom_boxplot()
@
We will now continue and start creating the matrices. For this, first we calculate the average rates for the transition from day 1 to 2 and the one from day 2 to 3. This will allow us to make on matrix and thus one value of $\lambda$ per clone
<<RateAVG,eval=FALSE>>=
# Averages
Rates$SaM <- (Rates$Sa1 + Rates$Sa2)/2
Rates$MM <- ...
Rates$SjM <- ...
Rates$RM <- ...
@
<<RateAVG3,echo=FALSE>>=
# Averages
Rates$SaM <- (Rates$Sa1 + Rates$Sa2)/2
Rates$MM <- (Rates$M1 + Rates$M2)/2
Rates$SjM <- (Rates$Sj1 + Rates$Sj2)/2
Rates$RM <- (Rates$R1 + Rates$R2)/2
@
Now we create a new column with the name \texttt{lambda} and using a for-loop, we can now for each replicate calculate the value for lambda, by constructing the appropriate matrix.
<<lams,eval=FALSE>>=
Rates$lambda <- 0 # create empty column
for(i in 1:nrow(Rates)){ # for each row in Rates
  Mat <- ...
  Rates$lambda[i] <- ...
}
@
We can now again use the boxplot commands that we used before to see how lambda varies among matrices.
<<RateAVG2,echo=TRUE>>=
Rates2 <- Rates[,c('Copper','Layer','SaM','MM','SjM','RM')]
Rates3 <- aggregate( .~ Copper+Layer,Rates2,mean)
Rates3$lambda <- NA
Rates$lambda <- NA
for(i in 1:nrow(Rates3)){
  Mat <- matrix(c(Rates3$SjM[i],Rates3$MM[i],Rates3$RM[i],Rates3$SaM[i]),nrow=2)
  Rates3$lambda[i] <- eigen(Mat)$values[1]
}

for(i in 1:nrow(Rates)){
  Mat <- matrix(c(Rates$SjM[i],Rates$MM[i],Rates$RM[i],Rates$SaM[i]),nrow=2)
  Rates$lambda[i] <- eigen(Mat)$values[1]
}
# boxplot(lambda~Copper+Layer,Rates)
@
\subsection{Factorial LTRE}
\begin{mdframed}
\textbf{Fixed Factorial Designs (Theory)}
Factorial LTRE allows the examination of the effects of several treatments and their interactions. This is the case for your rotifer data where you have a "layer" treatment and a "copper" treatment. We can no longer just compare two treatments with each other, instead we have a whole suite of treatments (9 in total, 3 layers times 3 copper levels). We thus have two factors, both with three levels.

A factorial LTRE is similar to a one-way LTRE; we want to find which differences in matrix elements between a focal matrix and a reference matrix contribute the most to the difference in $\lambda$ between the two matrices. Let us take the matrix "recovery layer and low copper" which we call $\boldsymbol{M}^{r,l}$ as the focal matrix, for this we average the rates over all the replicates that were subject to this treatment ($r,l$). We compare it to the matrix naive to any treatment, which we call $\boldsymbol{M}^{..}$. This matrix is obtained from taking the average rates for all the data. Again we are interested in understanding the effect of the different treatments on the asymptotic growth rates.
\begin{equation}\label{b}
\lambda^{r,l}=\lambda^{..}+\alpha^{r}+\beta^{l}+(\alpha \beta)^{r,l}
\end{equation}
Equation \ref{b} tells us that $\lambda^{r,l}$ can be found from the average matrix (with $\lambda^{..}$) plus an effect from the layer "recovery" ($\alpha^r$), an effect from the copper level "low" ($\beta^l$) and an interaction between the two treatments ($(\alpha \beta)^{r,l}$).

To isolate the effect of each factor, we need to look at them separately. So we examine a matrix $\boldsymbol{M}^{r.}$, where the effect of copper is ignored. The rates of this matrix are calculated as the average of all the matrices with from the layer "recovery". 
\begin{equation}\label{c}
\alpha^{r}=\sum_{ij}(a^{r.}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{A}}{\partial a^{A}_{ij}}
\end{equation}
The structure of equation \ref{c} is the same as the last part of equation \ref{a}. The matrix $\boldsymbol{A}$ is again a "mid-way" matrix between $\boldsymbol{M}^{r.}$ and $\boldsymbol{M}^{..}$. $\alpha^{r}$ tells us how large the effect of the treatment "layer" is on the asymptotic growth rate. If we want to know which matrix elements are responsible for this effect, we need to look at the separate contributions to $\alpha^r$ ($(a^{r.}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{A}}{\partial a^{A}_{ij}}$). Analogously we can also calculate the effects for the other layers, e.g. $\alpha^{peak}$.

We do the same for the second factor. We examine a matrix $\boldsymbol{M}^{.l}$, where the effect of the layer is ignored: 
\begin{equation}\label{d}
\beta^{l}=\sum_{ij}(a^{.l}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{B}}{\partial a^{B}_{ij}}
\end{equation}
For the interaction effect, we apply the same logic. We examine a matrix $\boldsymbol{M}^{rl}$ where both the effects of the layer and the copper level are taken into account so as to capture the effect of the interaction between the two factors. Because we want to isolate the interaction effect, we need to remove the effects of the layer and copper treatment.
\begin{equation}
(\alpha \beta)^{rl}=\sum_{ij}(a^{rl}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{C}}{\partial a^{C}_{ij}} -\alpha^{r}-\beta^{l}
\end{equation}
So far we have considered only the effect of the layer "recovery" and the copper level "low". Of course this can be extended to all other layers of all treatments. So in general the equations become for the $k^{th}$ level of treatment $1$ and the $m^{th}$ the level of treatment $2$.

\begin{equation}\label{f}
\lambda^{k,m}=\lambda^{..}+\alpha^{k}+\beta^{m}+(\alpha \beta)^{k,m}
\end{equation}
\begin{equation}\label{e}
\alpha^{k}=\sum_{ij}(a^{k.}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{A}}{\partial a^{A}_{ij}}
\end{equation}
\begin{equation}
\beta^{m}=\sum_{ij}(a^{.m}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{B}}{\partial a^{B}_{ij}}
\end{equation}
\begin{equation}
(\alpha \beta)^{km}=\sum_{ij}(a^{km}_{ij}-a^{..}_{ij}) \frac{\partial\lambda^{C}}{\partial a^{C}_{ij}} -\alpha^{k}-\beta^{m}
\end{equation}
In these equations:
\begin{align}
A &= \frac{\boldsymbol{M^{k.}} + \boldsymbol{M^{..}}}{2} & B &= \frac{\boldsymbol{M^{.m}} + \boldsymbol{M^{..}}}{2} & C &= \frac{\boldsymbol{M^{km}} + \boldsymbol{M^{..}}}{2}
\end{align}
LTREs provide additional information to the growth rate as it describes how the different treatments affect the growth rate. In particular, LTRE allow a detailed comparison of the effect of a treatment on growth rate by examining the contribution of each survival and fertility rate to the growth rates of populations subjected to different treatment levels.
\end{mdframed}
We are now going to apply this theory on the rotifer data. First write a function that performs an \texttt{LTRE}. That is, if we give it two matrices as input, it calculates the sensitivities of the average matrix (you can call the function \texttt{sens}) and it multiplies this with the difference between the matrices. You don't have to use a loop here, if you use \texttt{A*B}, this is not matrix multiplication, but element wise multiplication between the matrices. To get the first element of the result, it simply multiplies the first matrix entry from A, with the first one from B. For the second element of the results, it multiplies the second from A with the second one from B, this is thus not the same as the matrix multiplication that we have used before!
<<example7>>=
A <- matrix(c(1,2,3,4),nrow=2)
B <- matrix(c(1,2,3,4),nrow=2)
A
B
A*B
@

<<LTRE_FACT,include=TRUE>>=

#### FACTORIAL DESIGN LTRE
LTRE <- function(A,B){
  M <- (A+B)/2
  (A-B) * sens(M)
}
@
Next, we will have to create the mean matrix, to which we will compare all other matrices. Simply take the means of all the rates (\texttt{mean}) and put these rates together in a matrix.
<<coffeehouse,eval=FALSE>>=
MatMean <- ...
@

<<LTRE_FACT2,echo=TRUE>>=
MatMean <- matrix(c(mean(Rates$SjM),mean(Rates$MM),mean(Rates$RM),mean(Rates$SaM)),nrow=2)
@
Now we proceed and calculate the effect of copper on $\lambda$. For this we have to calculate an average matrix for each copper treatment and compare these with the overall average matrix. To obtain the average matrix, we again use \texttt{aggregate}, but this time we supply a formule: \texttt{.$\sim$Copper}, this means that \texttt{aggregate} will apply the function (in this case we will use \texttt{mean}) on all columns, per coppr level. To make sure that we don't end up with lots of columns, we first take a subset of \texttt{Rates} that only contains the relevant columns.
<<Polka>>=
### Copper treatment
temp  <- Rates[,c('Copper','SaM','MM','SjM','RM')]
tempc <- aggregate(.~Copper,temp,mean)
@
Next, we have to build a matrix for each row in \texttt{tempc} and perform an LTRE on each of these matrices compared to the overall mean matrix. To make sure that we can store the result afterwards, we first create an empty list with the right length. Complete the code to obtain the effects of copper through the different matrix elements on $\lambda$.
<<Shostakov,eval=FALSE>>=
copper_effect <- list(3)
for(i in 1:3){
  mat <- ...
  copper[[i]] <- ...
}
@
Finally, we add the names of the copper levels to this list, so we can easily find the right matrix back:
<<konijn,eval=FALSE>>=
names(copper_effect) <- tempc$Copper

# now we can obtain specific copper levels
# by naming them
copper_effect[['100']]
@
What are the total effects of the different copper levels on $\lambda$? Repeat the same procedure for the layer effect.
<<Trojka,echo=TRUE>>=
copper_effect <- list(3)
for(i in 1:3){
  mat <- matrix(c(tempc$SjM[i],tempc$MM[i],tempc$RM[i],tempc$SaM[i]),nrow=2)
  copper_effect[[i]] <- LTRE(mat,MatMean)
}
names(copper_effect) <- tempc$Copper

### Layer treatment
temp  <- Rates[,c('Layer','SaM','MM','SjM','RM')]
templ <- aggregate(.~Layer,temp,mean)
layer_effect <- list(3)
for(i in 1:3){
  mat <- matrix(c(templ$SjM[i],templ$MM[i],templ$RM[i],templ$SaM[i]),nrow=2)
  layer_effect[[i]] <- LTRE(mat,MatMean)
}
names(layer_effect) = templ$Layer
@
Finally, we have to calculate the interactions. Now we can use that we names the lists with the copper and layer effects to efficiently access them. We will have to access these in order to be able to substract the correct fixed effects from each interaction, as described in the theory at the beginning of this section.
<<LAST2,eval=FALSE>>=
temp2  <- Rates[,c('Copper','Layer','SaM','MM','SjM','RM')]
tempi <- aggregate(.~Copper+Layer,temp2,mean)
interaction <- list(9)
for(i in 1:9){
  mat <- ...
  interaction[[i]] <- ... - ...
}

@
What is left now is to plot the values and to examine the summed effect of each copper level, each layer level and each interaction. One way to plot for example the copper effects is by using \texttt{barplot(matrix(unlist(copper),nrow=4))}. 
<<LAST1,include=TRUE,eval=TRUE>>=
### Interactions
temp2  <- Rates[,c('Copper','Layer','SaM','MM','SjM','RM')]
tempi <- aggregate(.~Copper+Layer,temp2,mean)
interaction <- list(9)
for(i in 1:9){
  mat <- matrix(c(tempi$SjM[i],tempi$MM[i],tempi$RM[i],tempi$SaM[i]),nrow=2)
  interaction[[i]] <- LTRE(mat,MatMean) - layer_effect[[as.character(tempi$Layer[i])]] - copper_effect[[as.character(tempi$Copper[i])]]
}

### Plots
barplot(matrix(unlist(copper_effect),nrow=4),beside=T)

barplot(matrix(unlist(layer_effect),nrow=4),beside=T)
barplot(matrix(unlist(interaction),nrow=4),beside=T)

## Summary
sapply(copper_effect,sum)
sapply(layer_effect,sum)
sapply(interaction,sum)

### Outcome check

Rates3$lambda2 <- NA
Rates3$lambda3 <- NA
lam_mean <- lambda(MatMean)
for(i in 1:9){
  Rates3$lambda2[i] <- lam_mean + sum(copper_effect[[as.character(Rates3$Copper[i])]]) +sum(layer_effect[[as.character(Rates3$Layer[i])]]) + sum(interaction[[i]])
  Rates3$lambda3[i] <- lam_mean + sum(copper_effect[[as.character(Rates3$Copper[i])]]) +sum(layer_effect[[as.character(Rates3$Layer[i])]])
}
Rates3
@

If you manage to go through all the steps describe above, you should now know the asymptotic growth rates ($\lambda$) of your populations, have performed three LTRE analyses on your rotifer data and have plots to include in your report. The interpretation of the results is up to you.


\begin{center}
Good luck!
\end{center}

\begin{figure}[h]
\centering
\includegraphics[width=0.3\textwidth]{Hippocrate.jpg}
\caption{\label{fig:owl}random picture, from wikipedia.}
\end{figure}

\end{document}
